import os
import numpy as np
import cv2
from PIL import Image

import streamlit as st
from streamlit_drawable_canvas import st_canvas

import torch
import torch.nn.functional as F
from torchvision import transforms

import joblib
import re
from skimage.feature import hog
import pandas as pd


import html

# å‡è®¾è¿™äº›æ¨¡å‹å’Œæ•°æ®é›†å·¥å…·å·²å­˜åœ¨
from models.my_cnn import MyCNN
from models.advanced_cnn import AdvancedCNN

# fix_emnist_orientation, load_emnist å‡å®šæ¥è‡ª dataset.py

# =========================
# Streamlit å…¨å±€è®¾ç½® + ç®€å•æ ·å¼
# =========================

st.set_page_config(
    page_title="Handwritten Digit & Letter Recognition",
    page_icon="âœï¸",
    layout="centered"
)

st.markdown("""
<style>

@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700;800&display=swap');

html, body, [class*="css"] {
    font-family: 'Inter', sans-serif;
}

/* èƒŒæ™¯ */
.stApp {
    background: linear-gradient(180deg, #f7f9fc 0%, #eef1f5 100%);
}

/* ä¸»å®¹å™¨å±…ä¸­ & å®½åº¦ä¼˜åŒ– */
.main {
    max-width: 900px;
    margin: 0 auto;
}

/* æ ‡é¢˜ç¾åŒ– */
h1 {
    font-weight: 800 !important;
    letter-spacing: -0.5px;
    text-align: center;
    margin-top: -10px;
    color: #222;
}

h2 {
    font-weight: 700 !important;
    margin-bottom: 0.8rem;
    color: #333;
}

/* ç»ç’ƒæ‹Ÿæ€å¡ç‰‡æ•ˆæœ */
.card {
    background: rgba(255, 255, 255, 0.75);
    padding: 1.6rem 2rem;
    border-radius: 16px;
    box-shadow: 0 8px 20px rgba(0,0,0,0.06);
    margin-bottom: 1.8rem;
    backdrop-filter: blur(10px);
    transition: 0.25s ease;
}
.card:hover {
    transform: translateY(-3px);
    box-shadow: 0 12px 28px rgba(0,0,0,0.1);
}

/* ä¾§è¾¹æ  */
section[data-testid="stSidebar"] {
    background-color: #ffffffee;
    backdrop-filter: blur(4px);
    padding-left: 10px;
}

/* è¾“å…¥æ¡†ç¾åŒ– */
input, textarea {
    border-radius: 10px !important;
}

/* ä¸‹æ‹‰æ¡†ã€å•é€‰æŒ‰é’®æ–‡æœ¬ */
.stSelectbox label, .stRadio label {
    font-weight: 600;
    font-size: 15px;
}

/* æŒ‰é’® */
button[kind="secondary"] {
    border-radius: 12px !important;
}

/* æˆåŠŸæç¤ºç»“æœ */
.stAlert {
    border-radius: 12px;
    font-size: 1.15rem !important;
}

</style>
""", unsafe_allow_html=True)

# =========================
# EMNIST Balanced æ˜ å°„è¡¨ï¼ˆå®˜æ–¹ 47 ç±»ï¼‰
# =========================
EMNIST_LABEL_MAP = {
    0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9',
    10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J',
    20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T',
    30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z',

    # Lowercase â€” EMNIST Balanced official order
    36: 'a', 37: 'b', 38: 'c', 39: 'd', 40: 'e', 41: 'f', 42: 'g',
    43: 'h', 44: 'i', 45: 'j', 46: 'k'
}

# å‰ 10 ä¸ªç´¢å¼•æ˜¯æ•°å­—ï¼Œåé¢çš„æ˜¯å­—æ¯
DIGIT_IDX = list(range(10))  # 0-9
LETTER_IDX = list(range(10, 47))  # 10-46


# =========================
# æ¨¡å‹åŠ è½½
# =========================

@st.cache_resource
def load_cnn():
    """åŠ è½½è®­ç»ƒå¥½çš„ CNNï¼ˆ47 ç±» EMNIST Balancedï¼‰"""
    # å¿…é¡»ç¡®ä¿ cnn_model.pth æ–‡ä»¶å­˜åœ¨
    if not os.path.exists("cnn_model.pth"):
        st.error("æ¨¡å‹æ–‡ä»¶ cnn_model.pth æœªæ‰¾åˆ°ï¼è¯·ç¡®ä¿å®ƒåœ¨ app.py åŒçº§ç›®å½•ä¸‹ã€‚")
        return None
    model = MyCNN(num_classes=47)
    state = torch.load("cnn_model.pth", map_location="cpu")
    model.load_state_dict(state)
    model.eval()
    return model


@st.cache_resource
def load_logreg():
    """åŠ è½½ Logistic Regression åŸºçº¿æ¨¡å‹"""
    # å¿…é¡»ç¡®ä¿ logreg_model.pkl æ–‡ä»¶å­˜åœ¨
    if not os.path.exists("logreg_model.pkl"):
        st.error("æ¨¡å‹æ–‡ä»¶ logreg_model.pkl æœªæ‰¾åˆ°ï¼è¯·ç¡®ä¿å®ƒåœ¨ app.py åŒçº§ç›®å½•ä¸‹ã€‚")
        return None
    return joblib.load("logreg_model.pkl")


@st.cache_resource
def load_advancedcnn():
    """åŠ è½½è®­ç»ƒå¥½çš„ Advanced CNNï¼ˆ47 ç±» EMNIST Balancedï¼‰"""
    # å¿…é¡»ç¡®ä¿ advancedcnn_model.pth æ–‡ä»¶å­˜åœ¨
    if not os.path.exists("advancedcnn_model.pth"):
        st.error("æ¨¡å‹æ–‡ä»¶ advancedcnn_model.pth æœªæ‰¾åˆ°ï¼è¯·ç¡®ä¿å®ƒåœ¨ app.py åŒçº§ç›®å½•ä¸‹ã€‚")
        return None
    model = AdvancedCNN(num_classes=47)
    state = torch.load("advancedcnn_model.pth", map_location="cpu")
    model.load_state_dict(state)
    model.eval()
    return model


@st.cache_resource
def load_logreg_hog():
    """åŠ è½½ HOG + Logistic Regression æ¨¡å‹"""
    if not os.path.exists("logreg_hog.pkl"):
        st.error("æ¨¡å‹æ–‡ä»¶ logreg_hog.pkl æœªæ‰¾åˆ°ï¼")
        return None
    return joblib.load("logreg_hog.pkl")



# =========================
# é€‰æ‹©æ ‡ç­¾ï¼šè‡ªåŠ¨/åªæ•°å­—/åªå­—æ¯/å…¨ç±»
# =========================

def choose_label_by_mode(probs: np.ndarray, mode: str) -> int:
    if mode == "Digits only":
        candidate_idx = DIGIT_IDX

    elif mode == "Letters only":
        candidate_idx = LETTER_IDX

    elif mode == "All 47 classes":
        return int(np.argmax(probs))

    else:
        # Auto: çœ‹æœ€é«˜æ¦‚ç‡å±äºæ•°å­—è¿˜æ˜¯å­—æ¯
        best = int(np.argmax(probs))
        # 10æ˜¯Aï¼Œæ‰€ä»¥ <10 æ˜¯æ•°å­—
        if best < 10:
            return best  # 0â€“9
        else:
            return best  # 10â€“46ï¼ˆå­—æ¯ï¼‰

    # æ‰‹åŠ¨è¿‡æ»¤èŒƒå›´
    candidate_probs = probs[candidate_idx]
    # np.argmax è¿”å›çš„æ˜¯åœ¨ candidate_probs ä¸­çš„ç´¢å¼•ï¼Œéœ€è¦æ˜ å°„å›åŸå§‹ç´¢å¼•
    local_best = int(candidate_probs.argmax())
    return candidate_idx[local_best]


# =========================
# å›¾åƒé¢„å¤„ç†ï¼ˆä¸ dataset.py ä¿æŒä¸€è‡´çš„æ–¹å‘ï¼‰
# =========================

def preprocess_image(gray_img: np.ndarray):
    """
    æœ€ç»ˆç‰ˆï¼š100% å¤ç° EMNIST é¢„å¤„ç†æµç¨‹ï¼š
    - äºŒå€¼åŒ–ï¼ˆé»‘åº•ç™½å­—ï¼‰
    - bbox è£å‰ª
    - ç­‰æ¯”ç¼©æ”¾åˆ° 20x20
    - 28x28 padding å±…ä¸­
    - EMNIST æ—‹è½¬ + é•œåƒä¿®æ­£
    """

    # 1) uint8
    gray = gray_img.astype("uint8")

    # 2) OTSU + åè‰² â†’ é»‘åº•ç™½å­—
    _, img = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # 3) bbox è£å‰ª
    coords = cv2.findNonZero(img)
    if coords is None:
        canvas = np.zeros((28, 28), dtype=np.uint8)
        tensor = torch.zeros((1, 1, 28, 28))
        return canvas, canvas, tensor, canvas.reshape(1, -1) / 255

    x, y, w, h = cv2.boundingRect(coords)
    crop = img[y:y+h, x:x+w]

    # 4) ç­‰æ¯”ç¼©æ”¾åˆ°æœ€é•¿è¾¹=20
    scale = 20 / max(w, h)
    new_w = max(1, int(w * scale))
    new_h = max(1, int(h * scale))
    small = cv2.resize(crop, (new_w, new_h), interpolation=cv2.INTER_AREA)

    # 5) padding åˆ° 28Ã—28
    canvas = np.zeros((28, 28), dtype=np.uint8)
    y_off = (28 - new_h) // 2
    x_off = (28 - new_w) // 2
    canvas[y_off:y_off + new_h, x_off:x_off + new_w] = small

    # 6) â­â­ EMNIST æ–¹å‘ä¿®å¤ï¼ˆå¿…é¡»ä¿ç•™ï¼‰
    canvas = np.rot90(canvas, 3)
    canvas = np.fliplr(canvas)

    # è¾“å‡ºä¸¤å¼ å›¾ç”¨äº GUI æ˜¾ç¤º
    img_fixed = canvas.copy()
    img_resized = cv2.resize(gray, (28, 28))

    # è½¬ tensor
    tensor = torch.tensor(canvas / 255.0, dtype=torch.float32).unsqueeze(0).unsqueeze(0)
    flat = canvas.reshape(1, -1) / 255.0

    return img_resized, img_fixed, tensor, flat



# =========================
# å•å¼ å›¾åƒé¢„æµ‹
# =========================

def predict_single(gray_img: np.ndarray, model_name: str, category_mode: str):
    """
    è¿”å›ï¼šimg_resized, img_fixed, pred_idx, probs
    """

    img_resized, img_fixed, tensor, flat = preprocess_image(gray_img)
    model = None

    # ======================================================
    # 1) Logistic Regression
    # ======================================================
    if model_name == "Logistic Regression":
        clf = load_logreg()
        if clf is None: return img_resized, img_fixed, -1, None  # æ— æ³•åŠ è½½æ¨¡å‹

        if hasattr(clf, "predict_proba"):
            probs = clf.predict_proba(flat)[0]  # shape = (47,)
            pred_idx = choose_label_by_mode(probs, category_mode)
        else:
            pred_idx = int(clf.predict(flat)[0])
            probs = None

        return img_resized, img_fixed, pred_idx, probs

    # ======================================================
    # 2) MyCNN (ä½ çš„åŸºç¡€ CNN)
    # ======================================================
    elif model_name == "MyCNN":
        model = load_cnn()

    # ======================================================
    # 3) Advanced CNNï¼ˆé«˜çº§ CNNï¼‰
    # ======================================================
    elif model_name == "AdvancedCNN":
        model = load_advancedcnn()

    elif model_name == "HOG_LR":
        clf = load_logreg_hog()
        if clf is None:
            return img_resized, img_fixed, -1, None

        # ä½¿ç”¨ img_fixed è®¡ç®— HOG ç‰¹å¾ï¼ˆå’Œè®­ç»ƒä¸€è‡´ï¼‰
        feat = hog(
            img_fixed,
            orientations=9,
            pixels_per_cell=(4, 4),
            cells_per_block=(2, 2),
            block_norm="L2-Hys"
        ).reshape(1, -1)

        # è·å–æ¦‚ç‡
        if hasattr(clf, "predict_proba"):
            probs = clf.predict_proba(feat)[0]
            pred_idx = choose_label_by_mode(probs, category_mode)
        else:
            pred_idx = int(clf.predict(feat)[0])
            probs = None

        return img_resized, img_fixed, pred_idx, probs

    else:
        raise ValueError(f"æœªçŸ¥æ¨¡å‹åç§°: {model_name}")

    if model is None:
        return img_resized, img_fixed, -1, None  # æ— æ³•åŠ è½½æ¨¡å‹

    # ======================================================
    # æ·±åº¦å­¦ä¹ æ¨¡å‹é¢„æµ‹
    # ======================================================
    # ======================================================
    # æ·±åº¦å­¦ä¹ æ¨¡å‹é¢„æµ‹ï¼ˆâ­ åŠ å…¥â€œå¤šæ–¹å‘å°è¯•â€ï¼‰
    # ======================================================

    # æ‰€æœ‰å€™é€‰æ–¹å‘
    candidates = []

    # åŸå§‹ tensor
    candidates.append(("orig", tensor))

    # rot90 / rot180 / rot270
    for k in [1, 2, 3]:
        rotated = torch.rot90(tensor, k, [2, 3])
        candidates.append((f"rot{k}", rotated))

    # flipï¼ˆæ°´å¹³ç¿»è½¬ï¼‰
    flip = torch.flip(tensor, [3])
    candidates.append(("flip", flip))

    # flip åå† rot90 / rot180 / rot270
    for k in [1, 2, 3]:
        candidates.append((f"flip_rot{k}", torch.rot90(flip, k, [2, 3])))

    best_score = -1
    best_idx = None
    best_probs = None
    best_direction = None

    # é€ä¸ªæ–¹å‘å°è¯•
    with torch.no_grad():
        for name, t in candidates:
            logits = model(t)
            probs = F.softmax(logits, dim=1).cpu().numpy()[0]

            # é€‰æ‹©å¯¹åº”æ¨¡å¼ä¸‹æœ€å¥½çš„ç±»ï¼ˆdigit-only / letter-only / allï¼‰
            idx = choose_label_by_mode(probs, category_mode)
            score = probs[idx]  # è¯¥æ–¹å‘ä¸‹çš„å¯ä¿¡åº¦

            if score > best_score:
                best_score = score
                best_idx = idx
                best_probs = probs
                best_direction = name

    # ğŸ‘‰ å¦‚æœä½ æƒ³è°ƒè¯•çœ‹çœ‹é€‰äº†å“ªä¸ªæ–¹å‘ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Šï¼š
    # st.write(f"ä½¿ç”¨æ–¹å‘: {best_direction}")

    return img_resized, img_fixed, best_idx, best_probs


# =========================
# ä¾§è¾¹æ è®¾ç½®
# =========================

st.sidebar.title("âš™ï¸ Settings")
mode = st.sidebar.radio(
    "é€‰æ‹©æ¨¡å¼ / Mode",
    ("å•å¼ è¯†åˆ« Single Image", "æ¨¡å‹è¯„ä¼° Model Evaluation")
)

st.sidebar.markdown("---")  # åˆ†éš”çº¿

model_choice = st.sidebar.radio(
    "é€‰æ‹©æ¨¡å‹ / Model",
    ("CNN (MyCNN)", "Advanced CNN", "Logistic Regression (Baseline)", "HOG + Logistic Regression")
)


st.sidebar.markdown("---")  # åˆ†éš”çº¿

category_mode = st.sidebar.selectbox(
    "ç±»åˆ«èŒƒå›´ / Category range",
    ("Auto (Digit vs Letter)", "Digits only", "Letters only", "All 47 classes")
)

if model_choice == "Logistic Regression (Baseline)":
    current_model = "Logistic Regression"
elif model_choice == "CNN (MyCNN)":
    current_model = "MyCNN"
elif model_choice == "Advanced CNN":
    current_model = "AdvancedCNN"
elif model_choice == "HOG + Logistic Regression":
    current_model = "HOG_LR"


# =========================
# ä¸»æ ‡é¢˜
# =========================

st.markdown("""
<div style="text-align:center; margin-top:-20px;">
    <h1>ğŸ§  Handwritten Digit & Letter Recognition</h1>
    <p style="color:#555; font-size:16px;">
        æ”¯æŒ 0â€“9 ä¸ Aâ€“Z/aâ€“z æ‰‹å†™å­—ç¬¦è¯†åˆ« Â· åŸºäº EMNIST Balanced Â· å®æ—¶é¢„å¤„ç†ä¸æ¨¡å‹æ¨ç†
    </p>
</div>
""", unsafe_allow_html=True)


# =========================
# æ¨¡å¼ 1ï¼šå•å¼ è¯†åˆ«
# =========================

if mode.startswith("å•å¼ "):

    # ------ 1. è¾“å…¥æ–¹å¼ ------
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.subheader("1. è¾“å…¥æ–¹å¼ / Input")

    input_mode = st.radio(
        "é€‰æ‹©è¾“å…¥æ–¹å¼ï¼š",
        ("ä¸Šä¼ å›¾ç‰‡ Upload Image", "ç”»æ¿æ‰‹å†™ Draw on Canvas")
    )

    gray_img = None

    # ä¸Šä¼ å›¾ç‰‡
    if input_mode.startswith("ä¸Šä¼ "):
        uploaded = st.file_uploader(
            "ä¸Šä¼ ä¸€å¼ åŒ…å«å•ä¸ªæ•°å­—/å­—æ¯çš„å›¾ç‰‡ï¼ˆä»»æ„å¤§å°ï¼ŒèƒŒæ™¯å°½é‡ç®€å•ï¼‰",
            type=["png", "jpg", "jpeg"]
        )
        if uploaded is not None:
            # ç¡®ä¿è½¬æ¢ä¸ºç°åº¦å›¾ 'L'
            pil = Image.open(uploaded).convert("L")
            gray_img = np.array(pil)
            st.image(pil, caption="Original Image", use_container_width=True)

    # ç”»æ¿æ‰‹å†™
    else:
        st.write("åœ¨ä¸‹é¢ç”»ä¸€ä¸ªæ•°å­—æˆ–å­—æ¯ï¼š")
        # 200x200 ç”»å¸ƒï¼Œç™½è‰²èƒŒæ™¯ï¼Œé»‘è‰²ç¬”è¿¹
        canvas_result = st_canvas(
            fill_color="rgba(0,0,0,0)",
            stroke_color="#000000",
            background_color="#FFFFFF",
            stroke_width=10,
            width=200,
            height=200,
            drawing_mode="freedraw",
            key="canvas",
        )
        if canvas_result.image_data is not None:
            # st_canvas è¿”å›çš„æ˜¯ RGBA
            img_rgba = canvas_result.image_data.astype("uint8")
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray_img = cv2.cvtColor(img_rgba, cv2.COLOR_RGBA2GRAY)

    st.markdown('</div>', unsafe_allow_html=True)

    # ------ 2. é¢„å¤„ç† & é¢„æµ‹ ------
    if gray_img is not None:
        img_resized, img_fixed, pred_idx, probs = predict_single(
            gray_img, current_model, category_mode
        )

        # å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥
        if pred_idx == -1:
            st.warning("æ¨¡å‹åŠ è½½å¤±è´¥æˆ–æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ‚¨çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„å’Œåç§°ã€‚")
        else:
            # 2.1 æ˜¾ç¤ºé¢„å¤„ç†
            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.subheader("2. å›¾åƒé¢„å¤„ç† / Preprocessing")

            col1, col2 = st.columns(2)
            with col1:
                # åŸå§‹å›¾åƒç¼©æ”¾ç‰ˆæœ¬ (for display only)
                st.image(img_resized, caption="Resize 28Ã—28", width=150)
            with col2:
                # ç»è¿‡ EMNIST æ–¹å‘ä¿®æ­£å’Œé»‘ç™½åè½¬çš„ç‰ˆæœ¬ (Actual Input to Model)
                st.image(img_fixed, caption="Fixed Input", width=150)

            st.markdown('</div>', unsafe_allow_html=True)

            # 2.2 æ˜¾ç¤ºé¢„æµ‹ç»“æœ
            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.subheader("3. è¯†åˆ«ç»“æœ / Prediction")

            char_label = EMNIST_LABEL_MAP.get(pred_idx, f"class {pred_idx}")
            st.success(f"é¢„æµ‹ç±»åˆ«: {pred_idx} | å­—ç¬¦: {char_label}")

            if probs is not None:
                topk = 5
                # æ‰¾åˆ°æ¦‚ç‡æœ€é«˜çš„ Top-5 ç´¢å¼•
                top_idx = np.argsort(probs)[-topk:][::-1]
                st.write("Top-5 æ¦‚ç‡ï¼š")

                rows = []
                for rank, i in enumerate(top_idx, start=1):
                    label = EMNIST_LABEL_MAP.get(i, f"class {i}")
                    rows.append({
                        "Rank ": rank,
                        "ç±»åˆ« ID": int(i),
                        "å­—ç¬¦ Label": label,
                        "æ¦‚ç‡ Probability": f"{probs[i]:.4f}",
                    })

                df_top5 = pd.DataFrame(rows)


                # ç”¨ dataframe å±•ç¤ºï¼Œå»æ‰å·¦ä¾§ç´¢å¼•
                st.dataframe(df_top5, hide_index=True, use_container_width=True)

    else:
        st.info("è¯·å…ˆä¸Šä¼ å›¾ç‰‡æˆ–åœ¨ç”»æ¿ä¸Šä¹¦å†™ä¸€ä¸ªå­—ç¬¦ã€‚")

# =========================
# æ¨¡å¼ 2ï¼šæ¨¡å‹è¯„ä¼°
# =========================

else:
    # æ¨¡å¼è¯„ä¼°éƒ¨åˆ†ä¾èµ–äºæœ¬åœ°çš„æŠ¥å‘Šå’Œå›¾åƒæ–‡ä»¶ (å¦‚ .txt, .png)

    # =====================================
    #   1. Overall Metrics Summary
    # =====================================
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.subheader("1. æ¨¡å‹æ•´ä½“æ€§èƒ½ / Overall Metrics")

    # --- Logistic Regression (pixels) ----
    lr_pixels_acc = "N/A"
    if os.path.exists("logreg_pixels_classification_report.txt"):
        try:
            with open("logreg_pixels_classification_report.txt", "r", encoding="utf-8") as f:
                first_line = f.readline().strip()
            m = re.search(r"Accuracy:\s*([0-9.]+)", first_line)
            if m:
                lr_pixels_acc = f"{float(m.group(1)) * 100:.2f}%"
        except:
            pass

    # ---- HOG + Logistic Regression ----
    hog_acc_str = "N/A"
    if os.path.exists("logreg_hog_classification_report.txt"):
        try:
            with open("logreg_hog_classification_report.txt", "r", encoding="utf-8") as f:
                first_line = f.readline().strip()
            m = re.search(r"Accuracy:\s*([0-9.]+)", first_line)
            if m:
                hog_acc_str = f"{float(m.group(1)) * 100:.2f}%"
        except:
            pass

    # ---- CNN Accuracy ----
    cnn_acc = "N/A"
    if os.path.exists("cnn_test_accuracy.txt"):
        with open("cnn_test_accuracy.txt", "r") as f:
            try:
                v = float(f.read().strip())
                cnn_acc = f"{v * 100:.2f}%"
            except:
                pass

    # ---- Advanced CNN Accuracy ----
    adv_acc = "N/A"
    if os.path.exists("advancedcnn_test_accuracy.txt"):
        with open("advancedcnn_test_accuracy.txt", "r") as f:
            try:
                v = float(f.read().strip())
                adv_acc = f"{v * 100:.2f}%"
            except:
                pass

    st.write(f"**Logistic Regression (Pixels):** baselineï¼Œå‡†ç¡®ç‡çº¦ **{lr_pixels_acc}**")
    st.write(f"**HOG + Logistic Regression:** ä½¿ç”¨äººå·¥ç‰¹å¾åæå‡ï¼Œå‡†ç¡®ç‡çº¦ **{hog_acc_str}**")
    st.write(f"**CNN (Deep Learning):** è‡ªå®šä¹‰å·ç§¯ç½‘ç»œï¼Œæµ‹è¯•å‡†ç¡®ç‡çº¦ **{cnn_acc}**")
    st.write(f"**Advanced CNN:** æ›´æ·±çš„è‡ªå®šä¹‰å·ç§¯ç½‘ç»œï¼Œæµ‹è¯•å‡†ç¡®ç‡çº¦ **{adv_acc}**")

    st.info("æ¨¡å‹æ¯”è¾ƒé“¾ï¼šLogistic Regressionï¼ˆåƒç´ ï¼‰ â†’ HOG+LRï¼ˆç‰¹å¾å·¥ç¨‹ï¼‰ â†’ CNNï¼ˆæ·±åº¦å­¦ä¹ ï¼‰ â†’ Advanced CNNï¼ˆæ›´æ·±æ¨¡å‹ï¼‰")
    st.markdown('</div>', unsafe_allow_html=True)

    # =====================================
    #   2. CNN Learning Curves
    # =====================================
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.subheader("2. CNN å­¦ä¹ æ›²çº¿ / Learning Curves")

    if os.path.exists("learning_curve.png"):
        st.image("learning_curve.png", caption="CNN Learning Curve", use_container_width=True)
    if os.path.exists("loss_curve.png"):
        st.image("loss_curve.png", caption="CNN Loss Curve", use_container_width=True)
    if not os.path.exists("learning_curve.png") and not os.path.exists("loss_curve.png"):
        st.info("æœªæ‰¾åˆ°å­¦ä¹ æ›²çº¿å›¾ç‰‡ (learning_curve.png / loss_curve.png)")

    st.markdown('</div>', unsafe_allow_html=True)

    # =====================================
    #   3. Confusion Matrices (ALL MODELS)
    # =====================================
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.subheader("3. å„æ¨¡å‹æ··æ·†çŸ©é˜µ / Confusion Matrices")

    # ---- CNN ----
    st.markdown("### ğŸ”µ CNN Confusion Matrix")
    if os.path.exists("confusion_matrix.png"):
        st.image("confusion_matrix.png", caption="CNN Confusion Matrix", use_container_width=True)
    else:
        st.info("æœªæ‰¾åˆ° CNN æ··æ·†çŸ©é˜µï¼ˆconfusion_matrix.pngï¼‰")

    # ---- Advanced CNN ----
    st.markdown("### ğŸŸ  Advanced CNN Confusion Matrix")
    if os.path.exists("confusion_matrix_advancedcnn.png"):
        st.image("confusion_matrix_advancedcnn.png",
                 caption="Advanced CNN Confusion Matrix",
                 use_container_width=True)
    else:
        st.info("æœªæ‰¾åˆ° Advanced CNN æ··æ·†çŸ©é˜µï¼ˆconfusion_matrix_advancedcnn.pngï¼‰ï¼Œè¯·å…ˆè¿è¡Œ evaluate_advancedcnn_confusion.pyã€‚")

    # ---- HOG + LR ----
    st.markdown("### ğŸŸ¢ HOG + Logistic Regression Confusion Matrix")
    if os.path.exists("confusion_matrix_hog.png"):
        st.image("confusion_matrix_hog.png", caption="HOG + LR Confusion Matrix", use_container_width=True)
    else:
        st.info("æœªæ‰¾åˆ° HOG + LR æ··æ·†çŸ©é˜µï¼ˆconfusion_matrix_hog.pngï¼‰")

    # ---- Logistic Regression (Pixels) ----
    st.markdown("### âšª Logistic Regression (Pixels) Confusion Matrix")
    if os.path.exists("confusion_matrix_logreg.png"):
        st.image("confusion_matrix_logreg.png", caption="LR (Pixels) Confusion Matrix", use_container_width=True)
    else:
        st.info("æœªæ‰¾åˆ° LR (Pixels) æ··æ·†çŸ©é˜µï¼Œè¯·å…ˆè¿è¡Œ evaluate_logreg_pixels.py")

    st.markdown('</div>', unsafe_allow_html=True)

    # =====================================
    #   4. Full Classification Reports
    # =====================================
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.subheader("4. åˆ†ç±»æŠ¥å‘Š / Classification Reports")

    # --- LR Pixels ---
    st.markdown("### âšª Logistic Regression (Pixels) Report")
    try:
        with open("logreg_pixels_classification_report.txt", "r", encoding="utf-8") as f:
            st.code(f.read(), language="text")
    except:
        st.info("æœªæ‰¾åˆ° logreg_pixels_classification_report.txt")

    # --- HOG + LR ---
    st.markdown("### ğŸŸ¢ HOG + Logistic Regression Report")
    try:
        with open("logreg_hog_classification_report.txt", "r", encoding="utf-8") as f:
            st.code(f.read(), language="text")
    except:
        st.info("æœªæ‰¾åˆ° logreg_hog_classification_report.txt")

    # --- CNN ---
    st.markdown("### ğŸ”µ CNN Classification Report")
    try:
        with open("cnn_classification_report.txt", "r", encoding="utf-8") as f:
            st.code(f.read(), language="text")
    except:
        st.info("æœªæ‰¾åˆ° cnn_classification_report.txtï¼Œè¯·å…ˆè¿è¡Œ evaluate_cnn_report.py")

    # --- Advanced CNN ---
    st.markdown("### ğŸŸ  Advanced CNN Classification Report")
    try:
        with open("advancedcnn_classification_report.txt", "r", encoding="utf-8") as f:
            st.code(f.read(), language="text")
    except:
        st.info("æœªæ‰¾åˆ° advancedcnn_classification_report.txtï¼Œè¯·å…ˆè¿è¡Œ evaluate_advancedcnn_confusion.py")

    st.markdown('</div>', unsafe_allow_html=True)

    # =====================================
    #   5. Model Comparison Chart
    # =====================================
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.subheader("5. æ¨¡å‹æ€»ä½“å¯¹æ¯” / Model Comparison")

    if os.path.exists("model_comparison.png"):
        st.image("model_comparison.png", caption="Model Comparison", use_container_width=True)
    else:
        st.info("è¯·å…ˆè¿è¡Œ generate_model_comparison.py ç”Ÿæˆ model_comparison.png")

    st.markdown('</div>', unsafe_allow_html=True)
